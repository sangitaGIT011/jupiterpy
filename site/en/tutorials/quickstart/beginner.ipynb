{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import required libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 2: Load the Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 3: Drop unnecessary or mostly-empty columns\n",
        "df = df.drop(columns=['deck', 'embark_town', 'alive'])\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "df['age'] = df['age'].fillna(df['age'].mean())   # ✅ Fix: no inplace=True\n",
        "df = df.dropna(subset=['embarked'])              # Drop rows where 'embarked' is missing\n",
        "df = df.dropna()                                 # Drop any remaining missing data\n",
        "\n",
        "# Step 5: Convert categorical columns to numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object' or str(df[col].dtype) == 'category':\n",
        "        df[col] = label_encoder.fit_transform(df[col].astype(str))  # ✅ Fix: convert to str\n",
        "\n",
        "# Step 6: Normalize numerical columns using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "# Step 7: Split the data into features (X) and target (y)\n",
        "X = df.drop('survived', axis=1)  # Features\n",
        "y = df['survived']               # Target\n",
        "\n",
        "# Step 8: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 9: Train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 10: Predict and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n✅ Model Accuracy: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqRX3_TsX6g4",
        "outputId": "7c346f20-13b6-4f4f-beac-b883062f381e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model Accuracy: 80.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 3: Drop unnecessary or mostly empty columns\n",
        "df = df.drop(columns=['deck', 'embark_town', 'alive'])\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "df['age'] = df['age'].fillna(df['age'].mean())\n",
        "df = df.dropna(subset=['embarked'])\n",
        "df = df.dropna()\n",
        "\n",
        "# Step 5: Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object' or str(df[col].dtype) == 'category':\n",
        "        df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
        "\n",
        "# Step 6: Normalize numerical columns\n",
        "scaler = MinMaxScaler()\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "# Step 7: Split into features and target\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "# Step 8: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 9: Train Decision Tree Classifier\n",
        "tree_model = DecisionTreeClassifier(max_depth=4, random_state=42)  # Limit depth for clear visualization\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 10: Evaluate model\n",
        "y_pred = tree_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n Decision Tree Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "## Step 11: Visualize the tree\n",
        "#plt.figure(figsize=(20, 10))\n",
        "#plot_tree(tree_model, feature_names=X.columns, class_names=['Not Survived', 'Survived'],\n",
        " #         filled=True, rounded=True, fontsize=12)\n",
        "#plt.title(\"Decision Tree for Titanic Survival\")\n",
        "#plt.show()\n",
        "\n",
        "# Step 12: Predict on a new sample (e.g. hypothetical passenger)\n",
        "# NOTE: Input values must match the order and scaling of your features\n",
        "# Example: [pclass, sex, age, sibsp, parch, fare, embarked, class, who, adult_male, alone]\n",
        "# We'll use the first row from the training set as an example of a \"new passenger\"\n",
        "# Fix: Create a new DataFrame with correct feature names\n",
        "sample = pd.DataFrame([X.iloc[0].values], columns=X.columns)\n",
        "prediction = tree_model.predict(sample)#\n",
        "\n",
        "print(\"\\n Prediction for new sample:\", \"Survived\" if prediction[0] == 1 else \"Not Survived\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1mAZYFWYc6u",
        "outputId": "50f4eabc-2f5f-4765-93ca-b526d3272aae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Decision Tree Accuracy: 0.81\n",
            "\n",
            " Prediction for new sample: Not Survived\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ✅ Updated preprocessing function\n",
        "def preprocess(df, target_column):\n",
        "    df = df.copy()  # prevent chained assignment\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Label encode object and category columns\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object' or str(df[col].dtype) == 'category':\n",
        "            df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(target_column, axis=1)\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Decision tree pruning strategies\n",
        "pruning_params = [\n",
        "    {'max_depth': 3},\n",
        "    {'max_depth': 5},\n",
        "    {'min_samples_split': 10},\n",
        "    {'min_samples_leaf': 5},\n",
        "    {'max_leaf_nodes': 10}\n",
        "]\n",
        "\n",
        "# Datasets: (name, df, target_column)\n",
        "datasets = []\n",
        "\n",
        "# 1. Titanic\n",
        "titanic = sns.load_dataset('titanic')\n",
        "titanic = titanic.drop(columns=['deck', 'embark_town', 'alive'])\n",
        "datasets.append(('Titanic', titanic, 'survived'))\n",
        "\n",
        "# 2. Iris\n",
        "iris = load_iris(as_frame=True)\n",
        "datasets.append(('Iris', iris.frame, 'target'))\n",
        "\n",
        "# 3. Wine\n",
        "wine = load_wine(as_frame=True)\n",
        "datasets.append(('Wine', wine.frame, 'target'))\n",
        "\n",
        "# 4. Breast Cancer\n",
        "cancer = load_breast_cancer(as_frame=True)\n",
        "datasets.append(('Breast Cancer', cancer.frame, 'target'))\n",
        "\n",
        "# 5. Penguins\n",
        "penguins = sns.load_dataset('penguins')\n",
        "penguins = penguins.drop(columns=['island', 'species'])\n",
        "penguins = penguins[penguins['sex'].notna()]  # drop missing targets\n",
        "penguins['sex'] = penguins['sex'].map({'Male': 1, 'Female': 0})\n",
        "datasets.append(('Penguins', penguins, 'sex'))\n",
        "\n",
        "# Main loop to collect results\n",
        "results = []\n",
        "\n",
        "for dataset_name, df, target in datasets:\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = preprocess(df, target)\n",
        "\n",
        "        for params in pruning_params:\n",
        "            clf = DecisionTreeClassifier(**params, random_state=42)\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            results.append({\n",
        "                'Dataset': dataset_name,\n",
        "                'Pruning Method': str(params),\n",
        "                'Accuracy': round(acc * 100, 2)\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error with dataset {dataset_name}: {e}\")\n",
        "\n",
        "# Create summary table\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Pivot for comparison\n",
        "comparison_table = results_df.pivot(index='Dataset', columns='Pruning Method', values='Accuracy')\n",
        "print(\"\\n Decision Tree Pruning Comparison:\\n\")\n",
        "print(comparison_table.round(2))"
      ],
      "metadata": {
        "id": "pCDyD_I1iYWU",
        "outputId": "fae13839-9126-4c96-94f8-1f9e12ec5fa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Decision Tree Pruning Comparison:\n",
            "\n",
            "Pruning Method  {'max_depth': 3}  {'max_depth': 5}  {'max_leaf_nodes': 10}  \\\n",
            "Dataset                                                                      \n",
            "Breast Cancer              94.74             94.74                   94.74   \n",
            "Iris                      100.00            100.00                  100.00   \n",
            "Penguins                   83.58             86.57                   83.58   \n",
            "Titanic                    76.92             70.63                   74.83   \n",
            "Wine                       94.44             94.44                   94.44   \n",
            "\n",
            "Pruning Method  {'min_samples_leaf': 5}  {'min_samples_split': 10}  \n",
            "Dataset                                                             \n",
            "Breast Cancer                     95.61                      94.74  \n",
            "Iris                             100.00                     100.00  \n",
            "Penguins                          85.07                      85.07  \n",
            "Titanic                           79.02                      72.03  \n",
            "Wine                              94.44                      94.44  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "beginner.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}